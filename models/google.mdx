---
title: Gemini
---

Use Google's Gemini models through Google AI Studio - a platform providing access to large language models. Learn more [here](https://ai.google.dev/aistudio).

We recommend experimenting to find the best-suited model for your use-case. Here are some general recommendations:

- `gemini-1.5-flash` is good for most use-cases.
- `gemini-1.5-flash-8b` is their most cost-effective model.
- `gemini-2.0-flash-exp` is their strongest multi-modal model.

## Authentication

You can use Gemini models through either Google AI Studio or Google Cloud's Vertex AI:

### Google AI Studio

Set your `GOOGLE_API_KEY` environment variable. You can get one [from Google here](https://ai.google.dev/aistudio).

<CodeGroup>

```bash Mac
export GOOGLE_API_KEY=***
```

```bash Windows
setx GOOGLE_API_KEY ***
```

</CodeGroup>

### Vertex AI

To use Vertex AI:

1. Install Google Cloud CLI and authenticate. More details [here](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal#setup-local).

```bash
gcloud auth application-default login
```

2. Enable Vertex AI API and set variables:

Export the following variables:

```bash
export GOOGLE_GENAI_USE_VERTEXAI="true"
export GOOGLE_CLOUD_PROJECT="your-gcloud-project-id"
export GOOGLE_CLOUD_LOCATION="your-gcloud-location"
```

Or update your Agent configuration:

```python
agent = Agent(
    model=Gemini(
        id="gemini-1.5-flash",
        vertexai=True,
        project_id="your-gcloud-project-id",
        location="your-gcloud-location",
    ),
)
```

## Example

Use `Gemini` with your `Agent`:

<CodeGroup>

```python agent.py
from agno.agent import Agent
from agno.models.google import Gemini

# Using Google AI Studio
agent = Agent(
    model=Gemini(id="gemini-1.5-flash"),
    markdown=True,
)

# Or using Vertex AI
agent = Agent(
    model=Gemini(
        id="gemini-1.5-flash",
        vertexai=True,
        project_id="your-project-id",  # Optional if GOOGLE_CLOUD_PROJECT is set
        location="us-central1",  # Optional
    ),
    markdown=True,
)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story.")
```

</CodeGroup>

<Note> View more examples [here](../examples/models/gemini). </Note>

## Grounding and Search

Gemini models support grounding and search capabilities through optional parameters. This automatically sends tools for grounding or search to Gemini. See more details [here](https://ai.google.dev/gemini-api/docs/grounding?lang=python).

To enable these features, set the corresponding parameter when initializing the Gemini model:

To use grounding:

<CodeGroup>

```python
from agno.agent import Agent
from agno.models.google import Gemini

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp", grounding=True),
    show_tool_calls=True,
    markdown=True,
)

agent.print_response("Any news from USA?")
```

</CodeGroup>

To use search:

<CodeGroup>

```python
from agno.agent import Agent
from agno.models.google import Gemini

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp", search=True),
    show_tool_calls=True,
    markdown=True,
)

agent.print_response("What's happening in France?")
```

</CodeGroup>

Set `show_tool_calls=True` in your Agent configuration to see the grounding or search results in the output.

## Parameters

<Snippet file="model-google-params.mdx" />

`Gemini` is a subclass of the [Model](/reference/models/model) class and has access to the same params.
