---
title: Gemini
---

Use Google's Gemini models through [Google AI Studio](https://ai.google.dev/gemini-api/docs) or [Google Cloud Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/overview) - platforms that provide access to large language models and other services.

We recommend experimenting to find the best-suited model for your use case. Here are some general recommendations in the Gemini `2.x` family of models:

- `gemini-2.0-flash` is good for most use-cases.
- `gemini-2.0-flash-lite` is the most cost-effective model.
- `gemini-2.5-pro-exp-03-25` is the strongest multi-modal model.

Refer to the [Google AI Studio documentation](https://ai.google.dev/gemini-api/docs/models) and the [Vertex AI documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models) for information on available model versions.

## Authentication

You can use Gemini models through either Google AI Studio or Google Cloud's Vertex AI:

### Google AI Studio

Set the `GOOGLE_API_KEY` environment variable. You can get one [from Google AI Studio](https://ai.google.dev/gemini-api/docs/api-key).

<CodeGroup>

```bash Mac
export GOOGLE_API_KEY=***
```

```bash Windows
setx GOOGLE_API_KEY ***
```

</CodeGroup>

### Vertex AI

To use Vertex AI:

1. Refer to the [Vertex AI documentation](https://cloud.google.com/vertex-ai/docs/start/cloud-environment) to set up a project and development environment

1. Install the Google Cloud CLI and authenticate:
```bash
gcloud auth application-default login
```

2. Set the project ID environment variable (alternatively, you set `project_id` in the `Agent`):
```bash
export GOOGLE_CLOUD_PROJECT=your-project-id
```

## Example

Use `Gemini` with your `Agent`:

<CodeGroup>

```python agent.py
from agno.agent import Agent
from agno.models.google import Gemini

# Using Google AI Studio
agent = Agent(
    model=Gemini(id="gemini-2.0-flash"),
    markdown=True,
)

# Or using Vertex AI
agent = Agent(
    model=Gemini(
        id="gemini-2.0-flash",
        vertexai=True,
        project_id="your-project-id",  # Optional if GOOGLE_CLOUD_PROJECT is set
        location="us-central1",  # Optional
    ),
    markdown=True,
)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story.")
```

</CodeGroup>

<Note> View more examples [here](../examples/models/gemini). </Note>

## Grounding and Search

Gemini models support grounding and search capabilities through optional parameters.  This automatically sends tools for grounding or search to Gemini.  See more details [here](https://ai.google.dev/gemini-api/docs/grounding?lang=python).

To enable these features, set the corresponding parameter when initializing the Gemini model:

To use grounding:

<CodeGroup>

```python
from agno.agent import Agent
from agno.models.google import Gemini

agent = Agent(
    model=Gemini(id="gemini-2.0-flash", grounding=True),
    show_tool_calls=True,
    markdown=True,
)

agent.print_response("Any news from USA?")
```

</CodeGroup>

To use search:

<CodeGroup>

```python
from agno.agent import Agent
from agno.models.google import Gemini

agent = Agent(
    model=Gemini(id="gemini-2.0-flash", search=True),
    show_tool_calls=True,
    markdown=True,
)

agent.print_response("What's happening in France?")
```

</CodeGroup>

Set `show_tool_calls=True` in your Agent configuration to see the grounding or search results in the output.

## Parameters

<Snippet file="model-google-params.mdx" />

`Gemini` is a subclass of the [Model](/reference/models/model) class and has access to the same params.
